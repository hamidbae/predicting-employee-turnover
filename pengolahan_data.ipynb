{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from BGWOPSO import BGWOPSO\n",
    "# from GWO import GWO\n",
    "import functools\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1470, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/employee.csv\")\n",
    "attrition = data[\"Attrition\"]\n",
    "data = data.drop(\"Attrition\",axis=1)\n",
    "data[\"Attrition\"] = attrition\n",
    "# data.to_csv(\"./data/employee_class_right.csv\", index=False)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"Attrition\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectList = data.select_dtypes(include = \"object\").columns.to_list()\n",
    "nonObjectList = data.select_dtypes(exclude=\"object\").columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [\"Education\", 'EnvironmentSatisfaction', \"JobInvolvement\", \"JobLevel\", \"JobSatisfaction\", \"PerformanceRating\", \"RelationshipSatisfaction\", \"StockOptionLevel\", \"WorkLifeBalance\"]:\n",
    "    nonObjectList.remove(x)\n",
    "    objectList.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(nonObjectList)\n",
    "# print(objectList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data_encoded = data.copy()\n",
    "\n",
    "for object in objectList:\n",
    "    le.fit(data[object])\n",
    "    data_encoded[object] = le.transform(data[object])\n",
    "    # pickle.dump(le, open('./model/encode/{}.pkl'.format(object), 'wb'))\n",
    "\n",
    "# data.to_csv(\"./data/data_encoded.csv\", index=False)\n",
    "# pickle.dump(scaler, open('./model/minmaxscaler.pkl', 'wb'))\n",
    "# data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sort(data_encoded['MonthlyIncome'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_normalized = data.copy()\n",
    "\n",
    "for column in data_encoded.columns:\n",
    "    scaler.fit(data_encoded[column].values.reshape(-1,1))\n",
    "    data_normalized[column] = scaler.transform(data_encoded[column].values.reshape(-1,1))\n",
    "#     pickle.dump(scaler, open('./model/scale/{}.pkl'.format(column), 'wb'))\n",
    "# data_normalized.to_csv(\"./data/data_normalized.csv\", index=False)\n",
    "# data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_normalized.drop(\"Attrition\", axis=1).values\n",
    "y = data_normalized[\"Attrition\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_index = [data_normalized.columns.get_loc(c) for c in objectList if c in data_normalized.drop('Attrition', axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True, stratify=y)\n",
    "# X_train.to_csv(\"./data/X_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleksi Fitur BGWOPSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(x, X_train, X_test, y_train, y_test):\n",
    "    alpha = 0.99\n",
    "    beta = 1-alpha\n",
    "    if x.ndim == 1:\n",
    "        x = x.reshape(1, -1)\n",
    "    loss = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        if np.sum(x[i, :]) > 0:\n",
    "            model = SVC(C=10, gamma=0.1, kernel='rbf')\n",
    "            model.fit(X_train[:, x[i,:].astype(bool)], y_train)\n",
    "            acc = model.score(X_test[:, x[i,:].astype(bool)], y_test)\n",
    "            error_rate = 1 - acc\n",
    "            loss[i] = alpha * error_rate + beta * (np.sum(x[i, :]) / X.shape[1])\n",
    "        else:\n",
    "            loss[i] = np.inf\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.60144532  0.61845454  0.02559287  0.96576098  1.46147053  0.11487318\n",
      "  1.08011407  0.04493805  0.50519952  0.6211255   0.21317951  0.60712241\n",
      "  1.17275865  1.01093083  1.09198628  0.87746488  1.19297656  1.17415549\n",
      "  1.03401165  0.12502933 -0.43912786  1.06852289  0.8890102   0.2523591\n",
      "  0.24181025  0.68269579  1.61164147  1.09858576  0.65697997  0.41609731\n",
      "  0.57783158  1.17003482 -0.12492567  0.76493998]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[ 1.07717332  0.80374776  0.03516524  0.29307622  0.91443023 -0.10180933\n",
      "  1.53158634  0.24389935  0.96955371  0.12679692  0.73206668  0.74024026\n",
      "  0.01983931  0.91288759  0.98788435  0.89122948  1.06701482  1.12195512\n",
      "  0.83936643  0.63887905  0.45501108  0.4551476   0.86150382  0.19207133\n",
      "  0.45901706 -0.0116464   1.27498154  1.11293163  1.23266777 -0.04326519\n",
      "  0.36104548  0.99500661 -0.15631199  0.82751289]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 1.44258125 -0.20881877  0.82390651  0.29536976  1.0106032  -0.02932472\n",
      "  0.95529384 -0.36056378  1.02644     0.03290005  0.22316826  0.37104185\n",
      "  0.07353734  0.88989183  1.1387676   0.98193155  1.50113875  1.45534647\n",
      "  0.75095101 -0.20634914 -0.04958065  1.32673671  1.21722296 -0.05183048\n",
      "  0.55115603 -0.11072659  0.78998641  1.37030129  0.9898359   0.37076549\n",
      "  0.48297093  0.96165591  0.09755249  0.75902896]\n",
      "[1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      "[ 1.31547414  0.0877946   0.71875012  0.48121496  1.10500644 -0.31160193\n",
      "  1.19252862  0.24525499  0.97234148  0.27727198  0.62453886 -0.05003609\n",
      "  0.55515677  1.34080204  0.43140496  1.03710592  1.18564134  1.12478317\n",
      "  1.09695835  1.09766013  0.36750833  0.84479694  1.17155744  0.23895117\n",
      "  0.25164312  0.6156287   0.91903228  0.76030468  1.41621792  0.22805837\n",
      "  0.15544812  1.26769647 -0.27972643  1.08797582]\n",
      "[1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 0.91507908  1.03184503 -0.01532792 -0.37232265  0.55555868 -0.02875556\n",
      "  1.30842616  0.57940563  1.14753346  0.13729127 -0.34090657 -0.30420268\n",
      "  0.18760717  1.2396753   1.04690289  1.15789125  1.43197482  1.81935415\n",
      "  0.76878999  0.25230377  0.83660782  0.92667414  1.14162404  0.07604832\n",
      "  0.17721209  0.63047933  0.9973777   0.71812568  1.51616836 -0.15388434\n",
      "  0.71094472  1.04043954  0.1515642   0.61367666]\n",
      "[1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 1.35698043  0.04915548  0.49659636  0.14686586  0.46020011 -0.08062234\n",
      "  0.69678627  0.41710263  0.8671648   0.69416953  0.56357547  0.08307606\n",
      " -0.50657093  1.07500302  0.97163995  1.12401699  1.18918361  0.91538843\n",
      "  0.44932223  0.39761675  0.16002553  1.04549451  0.4946007   0.54422305\n",
      "  0.34419078  0.43406663  0.91856217  1.09674745  0.81600123  0.72849735\n",
      "  0.72923466  1.20553336  0.12487486  0.64101751]\n",
      "[1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[ 0.73852791  0.39016113  0.29790758  0.62678598  1.4093107   0.02590361\n",
      "  1.18915987  0.74967021  0.99138263  0.66383014 -0.33628246  0.36218399\n",
      "  0.37488411  1.22060373  0.83305671  0.83736726  1.16908584  0.70122308\n",
      "  0.90283164 -0.17979479  0.22942966  1.36849279  1.07551362  0.24461487\n",
      "  0.94509862 -0.23661814  0.47411113  0.98408202  1.05709113  0.29567062\n",
      " -0.04362565  0.72411588 -0.20994797  1.38674697]\n",
      "[0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 0. 1. 1. 1. 0. 0. 0. 0. 1.]\n",
      "[ 1.05419025  0.04865575  0.50920746 -0.14044968  0.98289767  0.16531888\n",
      "  0.70295412 -0.12056859  0.9946696   0.57818343  0.80737588  0.5144585\n",
      "  0.25752977  0.98616891  1.16466214  1.15034606  1.19852519  1.02884403\n",
      "  0.97465218  0.57100641  1.09530538  1.25362973  0.70550382  0.68525261\n",
      "  0.29633925 -0.7010309   0.41472199  0.92074224  1.26649648 -0.20192467\n",
      "  0.47703487  1.19832444  0.46909121  0.81062415]\n",
      "[1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 1. 0.]\n",
      "[ 1.32996393  0.88046916  0.32374099  0.08665089  1.33671849  0.06657996\n",
      "  1.12560489  1.16423987  1.30769707 -0.5377627   0.23169695 -0.56667611\n",
      "  0.80390867  1.00306337  1.13217718  1.01342113  1.10384134  1.09342226\n",
      "  0.9006561   0.26579711  0.03886634  1.11918817  0.72631103  0.0584476\n",
      "  1.21196027  0.90559969  1.41985102  1.05158791  0.80712113 -0.27474918\n",
      "  0.54239903  1.17538376  0.13048192  0.95112893]\n",
      "[1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 1.03973429 -0.12416017  0.18040456  0.19141873  0.94964199 -0.05337244\n",
      "  1.37553362  0.99541481  1.06440022 -0.01106186  0.14935901 -0.10913166\n",
      "  0.30484156  0.94878801  1.07454781  1.02104103  1.03411068  1.06452487\n",
      "  0.74171369  0.21395786  0.04342257  1.07056909  0.7431942   0.02507314\n",
      "  1.26989301  0.14929257  1.2334808   1.14377223  1.12581384 -0.10520587\n",
      "  1.17791208  0.99424795  0.18168956  0.98576841]\n",
      "[1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 1.242019    0.01312519  0.82044497 -0.03067533  1.08712465 -0.09748861\n",
      "  1.05650616  0.83528109  1.09589168 -0.06304185  0.45756505  0.12414872\n",
      "  0.22254275  1.10146687  1.15807466  1.07125242  1.27443562  1.24908565\n",
      "  0.6129659   0.13611588  0.06048214  1.26213173  1.20150645 -0.10994749\n",
      "  0.7626794   0.14161037  0.96499428  1.28624848  0.99138551  0.08835934\n",
      "  1.37871459  1.06002811  0.36270122  0.94785667]\n",
      "[1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[ 1.17165429  0.16012743 -0.25189006  0.02337114  1.13938496 -0.16951068\n",
      "  1.18783601  1.19525852  1.06594349  0.07223902  0.23532065 -0.10895414\n",
      "  0.45063074  1.18567546  1.07085775  1.10179618  1.09978067  1.06609043\n",
      "  0.8673465   0.63712235  0.87001671  0.99533662  0.75793701  0.05102516\n",
      "  1.27262399  0.2216233   1.03643226  0.94856289  1.22742463  0.04499506\n",
      "  1.14663974  1.22944788  0.00327732  1.12995704]\n",
      "[1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 0.95000119  0.8294211   0.31686642 -0.01789461  0.83521837 -0.01293089\n",
      "  1.25199527  1.22611028  1.16292732 -0.00525233 -0.09340472 -0.24965721\n",
      "  0.39948052  1.12969311  0.75075719  1.16866125  1.23614743  1.45059521\n",
      "  0.62523093  0.3830935   0.36164244  0.95642005  0.91833366 -0.03915558\n",
      "  1.00346157  0.6132806   0.99556055  0.92521319  1.2827558  -0.16644308\n",
      "  0.97105949  1.10364162  0.25368991  0.86739167]\n",
      "[1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 1.19463159  0.30901897  0.05253466  0.20555575  0.7824292  -0.04164361\n",
      "  0.91339998  0.85354248  1.00771915  0.30302768  1.21734693 -0.03526512\n",
      " -0.11456179  1.03853284  0.77907049  1.14990893  1.10174162  0.95017243\n",
      "  0.98115593  0.56332095  0.17339747  1.10643999  1.12517291 -0.15767118\n",
      "  1.09589863  0.33407     0.95192937  1.05057025  0.89515307 -0.0556595\n",
      "  0.93136296  1.19503525  0.13286097  0.88252718]\n",
      "[1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 0. 0.]\n",
      "[ 1.33492311  1.12134718  0.3629709   0.06151529  1.30784354  0.01732766\n",
      "  1.10172848  0.6738864   1.07648441 -0.2017662   0.0948396   0.89669647\n",
      "  0.86314949  1.11913536  0.96715033  0.99122365  1.09061577  0.8316135\n",
      "  0.71095981  0.09263705  0.29270301  1.28524731  0.85865017  0.05416051\n",
      "  1.05086223  0.13459512  0.79013014  0.98820025  1.02861707  0.08242425\n",
      "  0.88177271  1.35859951  0.06758095  1.29535257]\n",
      "[1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[ 1.02701118  0.36367934  0.20359692  0.03375056  0.98754461  0.094506\n",
      "  1.5816276   1.10774494  1.07830403 -0.13887118 -0.11190378 -0.17414842\n",
      "  0.43794746  0.98935552  0.75806796  1.16448434  1.10691299  1.01297987\n",
      "  0.76611988 -0.34702761  0.10238328  1.22166073  0.52422168  0.71132592\n",
      "  1.0694087  -0.17367957  1.04792501  1.03737887  1.14454094 -0.19303753\n",
      "  0.97576918  1.1910445   0.85349018  1.50640346]\n",
      "[1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 1.17967563  0.59948344  0.00810512  0.35917361  1.18341486  0.03984552\n",
      "  1.06654533  1.17217576  1.16734901 -0.29471012  0.04700932 -0.31071618\n",
      " -0.00796706  0.99870806  0.79535285  1.00444197  1.05449733  1.04872947\n",
      "  1.02625947  0.78470593 -0.17409268  1.06299312  0.92974448  0.03534356\n",
      "  0.78805462  0.59230797  1.22943587  1.02557057  0.89023717 -0.14910952\n",
      "  0.53472863  1.09410221 -0.0090219   0.96995788]\n",
      "[1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 1.01900856  0.93445306  0.31601646  0.35386259  0.96913473 -0.02655845\n",
      "  1.20490237  0.9029015   1.03266328 -0.00313591  0.00142819 -0.14166862\n",
      "  0.10535537  0.96866197  1.03828084  1.00866024  1.01589541  1.03273228\n",
      "  0.93827117  0.9600648   0.33438408  1.03607828  0.93909077  0.01686792\n",
      "  0.96279684  1.21951862  1.12626392  1.07660251  1.066661   -0.05525271\n",
      "  0.90526623  0.99382796  0.01932593  0.98913381]\n",
      "[1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 1.13099055  1.12513116  0.82961275  0.20523915  1.0452432  -0.05098055\n",
      "  1.02829324  0.62441784  1.05009651 -0.03191131  0.85795559 -0.49693547\n",
      "  0.42522813  1.05318285  0.84841798  1.03645656  1.14893593  1.13490255\n",
      "  0.8669982   1.33963757  0.17103102  1.14212468  1.10856337 -0.05787761\n",
      "  0.63723407  1.05238098  0.97763354  1.15547537  0.99224336 -0.03234037\n",
      "  1.29090596  1.03024294 -0.06022399  0.9681464 ]\n",
      "[1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 1.09203763  1.08704778  0.03183908  0.10223986  1.07417378 -0.09085096\n",
      "  1.10099561  0.91462479  1.03351761  0.0429783   0.04901536 -0.05732771\n",
      " -0.32592618  1.09979955  1.12048072  1.05336516  1.0522494   1.03359896\n",
      "  1.00781974  0.97765931  0.75382049  0.99443064  0.94725218  0.0312346\n",
      "  1.01521388  1.16312607  1.01718061  0.96853735  1.12291131  0.02789642\n",
      "  0.90056954  1.12403135 -0.07944058  1.06895462]\n",
      "[1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 9.69333575e-01  8.14374644e-01  4.71177960e-01  2.69276795e-01\n",
      "  9.05791413e-01 -4.17057800e-03  1.13651327e+00  8.37979428e-01\n",
      "  1.08720650e+00  8.01635240e-05 -1.32962408e-01 -1.35218954e-01\n",
      "  4.30563907e-01  1.06880851e+00  9.43277532e-01  1.09038073e+00\n",
      "  1.12774013e+00  1.24645542e+00  8.73787948e-01  9.51651007e-01\n",
      "  4.26500947e-01  9.72886965e-01  1.03604552e+00 -1.86881984e-02\n",
      "  9.98928494e-01  5.07590911e-01  9.94554599e-01  9.55611284e-01\n",
      "  1.15354187e+00 -8.91527774e-02  1.06523380e+00  1.05438677e+00\n",
      "  5.91843236e-02  9.23602099e-01]\n",
      "[1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 1.10475754  1.3278138   0.18714967  0.21704474  0.87656807 -0.02006554\n",
      "  0.94907166  0.59655262  1.00128543  0.17073966  0.93776236 -0.01653449\n",
      "  0.26286317  1.01834346  0.95895138  1.07999971  1.05333495  0.96942837\n",
      "  1.07082305  1.39971288  0.29096236  1.0559359   1.15054883 -0.08429677\n",
      "  1.05010036  1.16242758  0.97040099  1.0250072   0.93897043 -0.02782454\n",
      "  0.5738327   1.104981   -0.00770489  1.29086949]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 1.18242097  0.68972634  0.39137763  0.32248168  1.16743009  0.01258013\n",
      "  1.05332768  0.62049691  1.03935292 -0.10870716 -0.02875298  0.01572508\n",
      "  0.58188352  1.06296388  0.70247218  0.99215375  1.04717584  0.90379581\n",
      "  0.92124626  1.24477076  0.24659629  1.15492114  1.00300557  0.03297028\n",
      "  0.78517856  1.03151127  0.8808312   0.99048004  1.01285423 -0.24231191\n",
      "  0.82692578  1.19552789 -0.04384299  1.16051527]\n",
      "[1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 1.01196523  1.32635829  0.24291229  0.10623306  0.99011709  0.24725296\n",
      "  1.31899312  0.84099324  1.04036023 -0.07388936 -0.14320323 -0.09341834\n",
      "  0.06757405  0.99111958  0.94732467  1.08806845  1.05619775  1.00419769\n",
      "  0.9517821   0.73764318  0.30980769  1.1197205   0.81787064 -0.1551569\n",
      "  1.0354359   0.75127963  1.02354283  1.01770464  1.07702806 -0.1038751\n",
      "  0.68637549  1.10277178  0.01353478  1.27735009]\n",
      "[1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 1.09647813  1.02524417  0.30042116  1.07322824  1.09854812  0.0250457\n",
      "  1.03385078  0.00380188  1.08965429 -0.16015962  0.37554191 -0.16902035\n",
      "  0.09821283  0.99629702  0.69799792  0.99947123  1.02718118  1.02398817\n",
      "  1.01154909  1.02540154  0.17371486  1.03188433  0.95811974  0.02255348\n",
      "  1.17943516  0.86742686  1.1240247   1.01116772  0.93624905 -0.07955716\n",
      " -0.14667116  1.04910588 -0.00200661  0.98038132]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 1.00753509e+00  1.04496899e+00  2.90884675e-01  1.26455174e+00\n",
      "  9.79925635e-01 -1.17146045e-02  1.11044330e+00 -1.50750471e-01\n",
      "  1.01509415e+00  1.25178736e-03  2.36402604e-01 -7.54379852e-02\n",
      "  3.52223788e-01  9.79663925e-01  7.05109507e-01  1.00180640e+00\n",
      "  1.00581170e+00  1.01513235e+00  9.62840004e-01  8.51936695e-01\n",
      "  1.01547143e-02  1.01698465e+00  9.63293718e-01  1.23256267e-02\n",
      "  1.06065971e+00  1.04731514e+00  1.06691016e+00  1.03941830e+00\n",
      "  1.03391481e+00 -2.75993461e-02 -1.00557148e-01  9.93595464e-01\n",
      "  1.36863484e-02  9.90996848e-01]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 1.06952675  0.93442643  0.98693086  1.18955335  1.02205822 -0.02523434\n",
      "  1.01267496 -0.37121373  1.02474494 -0.01467787 -0.05613869 -0.27210874\n",
      "  1.14075978  1.0264535   0.69156976  1.01719406  1.07946107  1.07169238\n",
      "  1.17969724  1.26927347  0.58826301  1.07569045  1.05711138 -0.02905245\n",
      "  0.52939171  0.74492073  0.98463046  1.08308121  0.99271825 -0.01491539\n",
      "  0.73844611  1.01375429 -0.11459402  0.97937851]\n",
      "[1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 1.04796296  1.12944329  0.1692369   1.03783474  1.03807378 -0.04730604\n",
      "  1.05292197  0.06454089  1.0155671   0.02677997  0.3185127  -0.02874803\n",
      " -0.10924575  1.05225985  0.63883391  1.02655442  1.02593675  1.01561213\n",
      "  1.00134112  1.06888737  0.7299647   0.9939291   0.96781176  0.02027882\n",
      "  0.84983572  1.17155917  1.00652316  0.97959494  1.0650542   0.34331087\n",
      " -0.11661579  1.06567424 -0.04098941  1.03518453]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 9.80035714e-01  7.76939621e-01  4.73772943e-01  8.36563167e-01\n",
      "  9.44859662e-01  6.79008699e-04  1.07258405e+00 -1.14996230e-01\n",
      "  1.04528852e+00  3.03215972e-03  3.31474590e-01 -7.18675383e-02\n",
      "  5.79316174e-01  1.03510365e+00  5.66193684e-01  1.04704572e+00\n",
      "  1.06772737e+00  1.13344649e+00  9.27142992e-01  8.73644014e-01\n",
      "  7.37004047e-01  9.82002821e-01  1.01696651e+00  2.62166615e-01\n",
      "  7.08112860e-01  1.12880369e+00  9.93997720e-01  9.72439245e-01\n",
      "  1.08201085e+00 -4.63659476e-02  8.44353259e-01  1.02711997e+00\n",
      "  3.57513956e-02  9.54719409e-01]\n",
      "[1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 1.05500453e+00  1.03162888e+00  2.28616436e-01  7.18950730e-01\n",
      "  9.28682026e-01 -8.12021978e-03  9.68819001e-01  7.40306846e-02\n",
      "  9.97723815e-01  9.75068705e-02  7.85394157e-01 -6.16548156e-03\n",
      "  3.42583250e-01  1.00716690e+00  6.46625043e-01  1.04129894e+00\n",
      "  1.02653770e+00  9.80088194e-01  1.03621887e+00  1.30253032e+00\n",
      "  2.90101744e-01  1.02797755e+00  1.08035395e+00 -4.36777325e-02\n",
      "  8.18547853e-01  9.73214428e-01  9.80626620e-01  1.01085585e+00\n",
      "  9.63227100e-01 -1.24154940e-02  6.69381634e-02  1.05512823e+00\n",
      " -1.27753731e-03  1.15803350e+00]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 1.09799791  1.02607089 -0.13231618  1.20921091  1.08969917  0.00995197\n",
      "  1.02653367 -0.41635436  1.01879744 -0.05719098  0.32715553 -0.07254968\n",
      "  0.10800805  1.03186814  1.11372899  0.99266865  1.0231281   0.94375492\n",
      "  0.95341525  1.21675653  0.35444102  1.08277439  0.99867606  0.02123967\n",
      "  0.96233272  1.09869906  0.93104204  0.9917421   1.00412814 -0.21539535\n",
      "  0.71821509  1.10525372 -0.02128308  1.08587122]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 1.003636    1.26192225  1.03983228  0.93826909  0.99154117  0.05562092\n",
      "  1.17360234  0.59714543  1.01935508 -0.03791633  0.19576117 -0.04872731\n",
      "  0.26917558  0.99209614  0.70533451  1.04576568  1.02812251  0.999336\n",
      "  0.97031946  0.77894108  0.32695405  1.06328781  0.89618795 -0.16714755\n",
      "  0.71768398  0.59650451  1.0100452   1.00681326  1.03965387 -0.05451602\n",
      "  0.31382594  1.05390524  0.01048045  1.15054935]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 1.05042116  1.09522968  0.08505409  0.93434756  1.05156708  0.01685273\n",
      "  1.01575154  0.15497951  1.04664358  0.13405697  0.34015165 -0.09057952\n",
      " -0.02688561  0.9949623   1.31577166  0.9967195   1.01205934  1.01029173\n",
      "  1.00340563  1.0953168   0.01491125  1.01466294  0.97382789  0.01547307\n",
      "  1.18058765  1.37765059  1.06567056  1.00319451  0.96172059 -0.04105395\n",
      "  0.26462902  1.02419655  0.00187695  0.98615159]\n",
      "[1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 1.00118354  1.02190642  0.07977482  1.227707    0.98589933 -0.00349726\n",
      "  1.05815209  0.0840674   1.00536813  0.3252958   0.22328296 -0.03877363\n",
      "  0.1137313   0.98575445  0.91800761  0.99801222  1.00022949  1.00538927\n",
      "  0.97644096  1.29097419 -0.07563335  1.00641468  0.97669213  0.00981108\n",
      "  1.03059259  1.10744786  1.03405274  1.01883363  1.01578698 -0.01229083\n",
      "  0.06374154  0.99346676  0.01056435  0.9920282 ]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 1.03550126  1.04495425 -0.3779798   0.9713659   1.00922334 -0.01098159\n",
      "  1.0040289  -0.08690851  1.01071067  0.22103772  0.18989232 -0.14764781\n",
      "  0.8549972   1.01165651  1.10856231  1.00653061  1.04100075  1.03670012\n",
      "  1.0964901   0.91298617 -0.55714775  1.03891339  1.02862828 -0.01309525\n",
      "  1.26245819  0.94004655  0.98850385  1.04300481  0.99298114 -0.00526917\n",
      "  0.51126966  1.0046264  -0.06044986  0.98559645]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 1.02356384  1.06867021  0.01243232  0.72200197  1.01808933 -0.02320018\n",
      "  1.02630908  0.26130106  1.00562995  0.25276796  0.35812756 -0.01292673\n",
      " -0.14173178  1.02594254  0.88131837  1.01171237  1.01137044  1.00565487\n",
      "  0.99775464  0.80054567 -0.05126631  0.99365145  0.97919326  0.01421385\n",
      "  0.99812602  1.09198498  1.00062335  0.98571626  1.03302531  0.10879723\n",
      "  0.17554437  1.03336856 -0.01970338  1.01648988]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 0.98596027  0.95777176  0.93202495  0.57902109  0.9664873   0.00336367\n",
      "  1.03719373  0.27105771  1.02208331  0.42520242  0.37045271 -0.03679708\n",
      " -0.23744382  1.0164451   0.84110576  1.02305607  1.03450514  1.07088633\n",
      "  0.9566796   1.01130596 -0.0528555   0.98704923  1.00640464  0.84862278\n",
      "  0.91967023  1.15255878  0.99368944  0.98175497  1.04241228 -0.02267976\n",
      " -0.03604608  1.01202545  0.02277925  0.97194552]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 1.02746195e+00  1.09876416e+00  4.53039972e-02  7.48045888e-01\n",
      "  9.57531586e-01 -1.50745772e-03  9.79750853e-01  3.04184093e-01\n",
      "  9.95752154e-01  1.04358052e+00  3.84834274e-01 -4.25341993e-04\n",
      "  1.08394430e-01  1.00097971e+00  8.85631432e-01  1.01987473e+00\n",
      "  1.01170312e+00  9.85989320e-01  1.01706248e+00  9.38814118e-01\n",
      "  7.93414033e-02  1.01250020e+00  1.04149504e+00 -2.11915992e-02\n",
      "  9.80805493e-01  1.06642674e+00  9.86287386e-01  1.00302187e+00\n",
      "  9.76655255e-01 -3.88526142e-03  1.23472373e-01  1.02753044e+00\n",
      "  2.28055554e-03  1.08449735e+00]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 1.05126249  1.09568734 -0.15450325  0.97320588  1.04666842  0.00849705\n",
      "  1.01170089 -0.11098622  1.00741822  0.32877605  0.82436287 -0.0371747\n",
      " -0.04914961  1.01465398  1.14421364  0.99295368  1.00981561  0.96587573\n",
      "  0.97122355  0.77450608  0.11495872  1.04283496  0.9962793   0.01474577\n",
      "  0.97616014  1.05165064  0.95883806  0.99244076  0.9992975  -0.11625207\n",
      "  0.92526268  1.0552792  -0.00879424  1.04454933]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 0.99902506  1.14200871 -0.47437099  1.04708149  0.99232953  0.03377874\n",
      "  1.09311605  0.67872983  1.00772692  0.31599754  1.01373008 -0.02398697\n",
      "  0.06775697  0.99263675  0.91813217  1.02234746  1.01258044  0.99664464\n",
      "  0.98058149  0.62043552  0.70820719  1.03204746  0.93954332 -0.08954276\n",
      "  0.92496866  0.8578854   1.0025731   1.00078394  1.01896405 -0.02719152\n",
      "  0.34074439  1.0268534   0.00878961  1.08035423]\n",
      "[1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 1.02492467  1.04973004  0.05007254  1.55271288  1.02555903  0.01231722\n",
      "  1.00573205  0.00453963  1.02283345  1.09642736  0.42480047 -0.04715577\n",
      " -0.01189572  0.99422342  1.17181899  0.99519618  1.0036881   1.00270958\n",
      "  0.99889753  1.04977826 -0.26823343  1.00512941  0.98252371  0.01155346\n",
      "  1.09698302  1.2060743   1.03336652  0.99878066  0.97582127 -0.01973911\n",
      "  0.31728512  1.01040709  0.00402684  0.98934593]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 9.97667408e-01  1.00913931e+00  4.71500079e-02  1.12306763e+00\n",
      "  9.89206284e-01  1.05174879e-03  1.02920440e+00 -3.47163279e-02\n",
      "  9.99983939e-01  1.17289356e+00  2.49959987e-01 -1.84767570e-02\n",
      "  6.59478372e-02  9.89126081e-01  9.51622379e-01  9.95911809e-01\n",
      "  9.97139261e-01  9.99995645e-01  9.83970265e-01  1.24233410e+00\n",
      " -3.88817843e-02  1.00056330e+00  9.84109309e-01  8.41905713e-03\n",
      "  1.01394785e+00  1.05649385e+00  1.01586334e+00  1.00743825e+00\n",
      "  1.00575167e+00 -3.81624888e-03  2.20991148e-01  9.93395505e-01\n",
      "  8.83606045e-03  9.92599140e-01]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 1.01666522e+00  1.02189826e+00 -2.06256544e-01  1.06540342e+00\n",
      "  1.00211813e+00 -3.09147419e-03  9.99242558e-01 -1.29366197e-01\n",
      "  1.00294150e+00  1.02772282e+00  4.35919454e-01 -7.87479784e-02\n",
      "  6.96077628e-01  1.00346510e+00  1.05711079e+00  1.00062747e+00\n",
      "  1.01970966e+00  1.01732889e+00  1.05042778e+00  1.03308522e+00\n",
      " -3.05441417e-01  1.01855413e+00  1.01286043e+00 -4.26156409e-03\n",
      "  1.14230540e+00  9.63822825e-01  9.90648112e-01  1.02081908e+00\n",
      "  9.93126676e-01  7.08431653e-05 -2.58651287e-01  9.99573327e-01\n",
      " -3.04764161e-02  9.89038613e-01]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 1.01005683  1.03502709  0.00987014  0.92735905  1.00702622 -0.00985551\n",
      "  1.01157656  0.06339775  1.00012888  1.26685869  0.32990851 -0.00416827\n",
      " -0.07547295  1.01137365  0.93131173  1.00349602  1.00330673  1.00014268\n",
      "  0.99576922  0.97083974 -0.10963518  0.99349775  0.9854939   0.01085637\n",
      "  0.99597481  1.04793381  0.9973573   0.98910494  1.01529457  0.06321641\n",
      "  1.11834686  1.01548458 -0.00791974  1.00614078]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 0.98924002  0.97363525 -0.31828559  0.84820683  0.97846005  0.00484986\n",
      "  1.01760215 -0.30087099  1.00923723  1.33518761  0.70213629 -0.01738257\n",
      " -0.12845779  1.006116    0.90905059  1.00977574  1.01611378  1.0362539\n",
      "  0.97303065  1.00327104 -0.11051493  0.98984285  1.00055774  0.64545479\n",
      "  0.95254278  1.08146662  0.99351878  0.98691202  1.02049106  0.18632729\n",
      "  0.14764087  1.00366934  0.01559806  0.98148165]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      "[ 1.01221477e+00  1.05168668e+00  2.80674412e-02  9.41776592e-01\n",
      "  9.73502298e-01  2.15327482e-03  9.85802573e-01  2.53253574e-01\n",
      "  9.94660669e-01  7.30282541e-01  4.51243288e-01  2.75231894e-03\n",
      "  6.29934221e-02  9.97554573e-01  9.33699379e-01  1.00801459e+00\n",
      "  1.00349090e+00  9.89256102e-01  1.00645777e+00  1.04738321e+00\n",
      "  4.69100728e-02  1.00393215e+00  1.01998329e+00 -8.74359043e-03\n",
      "  9.86386407e-01  1.03378513e+00  9.89421106e-01  9.98685081e-01\n",
      "  9.84088893e-01  8.36955966e-04 -2.52314558e-01  1.01225268e+00\n",
      "  4.25026595e-03  1.04378877e+00]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[ 1.02539042  1.04998339 -0.08254305  1.06642201  1.0228472   0.00769163\n",
      "  1.00348967  0.25299431  1.00111884  1.38278622  0.29987038 -0.01759161\n",
      " -0.1084634   1.00512445  1.07684687  0.99311147  1.002446    0.9781215\n",
      "  0.98108198  0.95642458  0.06662732  1.02072505  0.99495249  0.01115083\n",
      "  0.9838148   1.02560529  0.97422554  0.99282753  0.99662332 -0.06136774\n",
      "  0.75891107  1.02761401 -0.00188058  1.0216741 ]\n",
      "[1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[ 0.9964725   1.07562625 -0.25961736  1.02307587  0.99276595  0.02168722\n",
      "  1.04855996 -0.32864027  1.00128973  0.74499372  0.588161   -0.01029107\n",
      "  0.0404971   0.99293603  1.36189205  1.00938346  1.00397658  0.99515474\n",
      "  0.9862624   1.13660383 -0.06689185  1.01475324  0.96354425 -0.04658184\n",
      "  0.95547592  0.91833957  0.99843665  0.9974462   1.00751045 -0.01206506\n",
      "  0.27677593  1.01187788  0.00785359  1.04149519]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[False  True  True  True  True False  True False  True  True  True False\n",
      " False  True  True  True  True  True  True  True False  True  True False\n",
      "  True False  True  True  True False False  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "lossfunc_bgwopso = functools.partial(fitness, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "optimizer_bgwopso = BGWOPSO(lossfunc_bgwopso, X_train.shape[1], 8, 70)\n",
    "optimizer_bgwopso.opt()\n",
    "selected_features_bgwopso = optimizer_bgwopso.gBest_X.astype(bool)\n",
    "print(selected_features_bgwopso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer_bgwopso.plot_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([3,4,5]).reshape(1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected = data.loc[:, np.append(selected_features_bgwopso, True)]\n",
    "# data_selected.to_csv(\"./data/data_selected.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train = pd.DataFrame(X_train[:, selected_features_bgwopso])\n",
    "# data_train[data.columns[-1]] = y_train\n",
    "# data_train.columns = data_selected.columns\n",
    "# data_train.to_csv(\"./data/data_train.csv\", index=False)\n",
    "\n",
    "# data_test = pd.DataFrame(X_test[:, selected_features_bgwopso])\n",
    "# data_test[data.columns[-1]] = y_test\n",
    "# data_test.columns = data_selected.columns\n",
    "# data_test.to_csv(\"./data/data_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. BusinessTravel\n",
      "1. DailyRate\n",
      "2. Department\n",
      "3. DistanceFromHome\n",
      "4. EducationField\n",
      "5. EmployeeNumber\n",
      "6. EnvironmentSatisfaction\n",
      "7. Gender\n",
      "8. JobLevel\n",
      "9. JobRole\n",
      "10. JobSatisfaction\n",
      "11. MaritalStatus\n",
      "12. MonthlyIncome\n",
      "13. MonthlyRate\n",
      "14. NumCompaniesWorked\n",
      "15. OverTime\n",
      "16. PercentSalaryHike\n",
      "17. RelationshipSatisfaction\n",
      "18. StockOptionLevel\n",
      "19. TotalWorkingYears\n",
      "20. TrainingTimesLastYear\n",
      "21. YearsInCurrentRole\n",
      "22. YearsSinceLastPromotion\n",
      "23. YearsWithCurrManager\n",
      "24. Attrition\n"
     ]
    }
   ],
   "source": [
    "# print(\"list of all selected features: \")\n",
    "# for i, feature in enumerate(data.columns[np.where(selected_features_bgwopso)], start=1):\n",
    "for i, feature in enumerate(data_selected):\n",
    "    print(f\"{i}. {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. BusinessTravel\n",
    "# 2. DailyRate\n",
    "# 3. Department\n",
    "# 4. DistanceFromHome\n",
    "# 5. EducationField\n",
    "# 6. EmployeeNumber\n",
    "# 7. EnvironmentSatisfaction\n",
    "# 8. Gender\n",
    "# 9. JobLevel\n",
    "# 10. JobRole\n",
    "# 11. JobSatisfaction\n",
    "# 12. MaritalStatus\n",
    "# 13. MonthlyIncome\n",
    "# 14. MonthlyRate\n",
    "# 15. NumCompaniesWorked\n",
    "# 16. OverTime\n",
    "# 17. PercentSalaryHike\n",
    "# 18. RelationshipSatisfaction\n",
    "# 19. StockOptionLevel\n",
    "# 20. TotalWorkingYears\n",
    "# 21. TrainingTimesLastYear\n",
    "# 22. YearsInCurrentRole\n",
    "# 23. YearsSinceLastPromotion\n",
    "# 24. YearsWithCurrManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88.44\n",
      "Precision  73.33\n",
      "Recall / Sensifity  45.83\n",
      "F1  56.41\n",
      "Specificity  96.75\n",
      "TN =  119\n",
      "FP =  4\n",
      "FN =  13\n",
      "TP =  11\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "\n",
    "svm3 = SVC(C=1000, gamma=0.01, kernel='rbf')\n",
    "svm3.fit(X_train[:, selected_features_bgwopso], y_train)\n",
    "y_pred3 = svm3.predict(X_test[:, selected_features_bgwopso])\n",
    "# svm3.fit(X_train, y_train)\n",
    "# y_pred3 = svm3.predict(X_test)\n",
    "# pickle.dump(svm3, open('./model/svm_model.pkl', 'wb'))\n",
    "\n",
    "\n",
    "print(\"Accuracy =\", round(accuracy_score(y_test,y_pred3)*100, 2))\n",
    "print(\"Precision \", round(precision_score(y_test, y_pred3)*100, 2))\n",
    "print(\"Recall / Sensifity \", round(recall_score(y_test, y_pred3)*100, 2))\n",
    "print(\"F1 \", round(f1_score(y_test, y_pred3)*100, 2))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred3).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print(\"Specificity \", round(specificity*100, 2))\n",
    "print(\"TN = \", tn)\n",
    "print(\"FP = \", fp)\n",
    "print(\"FN = \", fn)\n",
    "print(\"TP = \", tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluasi_test_data = data_test.copy()\n",
    "# evaluasi_test_data[\"Predicted\"] = y_pred3\n",
    "# evaluasi_test_data.to_csv(\"./data/evaluasi_test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# import matplotlib.pyplot as plt\n",
    "# confusion_matrix = metrics.confusion_matrix(y_test, y_pred3)\n",
    "# cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "# cm_display.plot()\n",
    "# plt.savefig(\"./images/confusion_matrix_employee.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted = [\"predicted_false\", \"predicted_true\"]\n",
    "# actual = [\"actual_false\", \"actual_true\"]\n",
    "# df_cf = pd.DataFrame(columns = predicted, index = actual)\n",
    "# df_cf[\"predicted_false\"] = [tn, fn]\n",
    "# df_cf[\"predicted_true\"] = [fp, tp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "# # g = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "# C = [1, 10, 100, 1000]\n",
    "# g = [0.001, 0.01, 0.1, 1]\n",
    "# df_acc = pd.DataFrame(columns = C, index = g)\n",
    "# df_prec = pd.DataFrame(columns = C, index = g)\n",
    "# df_sens = pd.DataFrame(columns = C, index = g)\n",
    "# df_f1 = pd.DataFrame(columns = C, index = g)\n",
    "# df_spec = pd.DataFrame(columns = C, index = g)\n",
    "\n",
    "# for i in C:\n",
    "#     for j in g:\n",
    "#         # print(i, j)\n",
    "#         svm3 = SVC(C=i, gamma=j, kernel='rbf')\n",
    "#         # svm3 = SVC(C=i, gamma=j, kernel='poly')\n",
    "#         # svm3 = SVC(C=i, gamma=j, kernel='sigmoid')\n",
    "#         svm3.fit(X_train[:, selected_features_bgwopso], y_train)\n",
    "#         y_pred3 = svm3.predict(X_test[:, selected_features_bgwopso])\n",
    "#         # svm3.fit(X_train, y_train)\n",
    "#         # y_pred3 = svm3.predict(X_test)\n",
    "\n",
    "#         accuracy = round(accuracy_score(y_test,y_pred3)*100, 2)\n",
    "#         df_acc[i][j] = accuracy\n",
    "        \n",
    "#         precision = round(precision_score(y_test, y_pred3)*100, 2)\n",
    "#         df_prec[i][j] = precision\n",
    "\n",
    "#         sensifity = round(recall_score(y_test, y_pred3)*100, 2)\n",
    "#         df_sens[i][j] = sensifity\n",
    "\n",
    "#         F1 = round(f1_score(y_test, y_pred3)*100, 2)\n",
    "#         df_f1[i][j] = F1\n",
    "\n",
    "#         tn, fp, fn, tp = confusion_matrix(y_test, y_pred3).ravel()\n",
    "#         specificity = round(tn/(tn+fp)*100, 2)\n",
    "#         df_spec[i][j] = specificity\n",
    "\n",
    "# print(\"Accuracy\")\n",
    "# print(df_acc)\n",
    "# df_acc.to_excel(\"cm/accuracy.xlsx\")\n",
    "\n",
    "# print(\"Precision\")\n",
    "# print(df_prec)\n",
    "# df_prec.to_excel(\"cm/precision.xlsx\")\n",
    "\n",
    "# print(\"Sensifity\")\n",
    "# print(df_sens)\n",
    "# df_sens.to_excel(\"cm/sensifity.xlsx\")\n",
    "\n",
    "# print(\"F1 Score\")\n",
    "# print(df_f1)\n",
    "# df_f1.to_excel(\"cm/f1.xlsx\")\n",
    "\n",
    "# print(\"Specifity\") \n",
    "# print(df_spec) \n",
    "# df_spec.to_excel(\"cm/specifity.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "\n",
    "# matrix_list = [\"Accuracy\", \"Precision\", \"Sensifity\", \"F1\", \"Specificity\"]\n",
    "# df_svm_linear = pd.DataFrame(columns = C, index = matrix_list)\n",
    "\n",
    "# for i in C:\n",
    "#     svm3 = LinearSVC(C=i)\n",
    "#     # svm3 = SVC(C=i, gamma=j, kernel='linear')\n",
    "#     svm3.fit(X_train[:, selected_features_bgwopso], y_train)\n",
    "#     y_pred3 = svm3.predict(X_test[:, selected_features_bgwopso])\n",
    "#     # svm3.fit(X_train, y_train)\n",
    "#     # y_pred3 = svm3.predict(X_test)\n",
    "\n",
    "#     accuracy = round(accuracy_score(y_test,y_pred3)*100, 2)\n",
    "#     df_svm_linear[i][\"Accuracy\"] = accuracy\n",
    "    \n",
    "#     precision = round(precision_score(y_test, y_pred3)*100, 2)\n",
    "#     df_svm_linear[i][\"Precision\"] = precision\n",
    "\n",
    "#     sensifity = round(recall_score(y_test, y_pred3)*100, 2)\n",
    "#     df_svm_linear[i][\"Sensifity\"] = sensifity\n",
    "\n",
    "#     F1 = round(f1_score(y_test, y_pred3)*100, 2)\n",
    "#     df_svm_linear[i][\"F1\"] = F1\n",
    "\n",
    "#     tn, fp, fn, tp = confusion_matrix(y_test, y_pred3).ravel()\n",
    "#     specificity = round(tn/(tn+fp)*100, 2)\n",
    "#     df_svm_linear[i][\"Specificity\"] = specificity\n",
    "\n",
    "# df_svm_linear.to_excel(\"cm/matrix_svm_linear.xlsx\")\n",
    "# print(df_svm_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluasi_test_data = pd.DataFrame(X_test[:, selected_features_bgwopso])\n",
    "# evaluasi_test_data.columns = data.columns[np.where(selected_features_bgwopso)]\n",
    "# evaluasi_test_data[\"Actual\"] = y_test\n",
    "# evaluasi_test_data[\"Predicted\"] = y_pred3\n",
    "# evaluasi_test_data.to_excel(\"evaluasi_test_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleksi Fitur GWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lossfunc_gwo = functools.partial(fitness, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "# fit_optimizer_gwo = GWO(lossfunc_gwo, 0, 1, X_train.shape[1], 10, 20)\n",
    "# selected_features_gwo = np.where(fit_optimizer_gwo>0.5)[0]\n",
    "# print(selected_features_gwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm2 = SVC(C=10, gamma=0.1, kernel='rbf')\n",
    "# svm2.fit(X_train[:, selected_features_gwo], y_train)\n",
    "# y_pred2 = svm2.predict(X_test[:, selected_features_gwo])\n",
    "\n",
    "# print(\"Accuracy \", accuracy_score(y_test,y_pred2))\n",
    "# print(\"Precision \", precision_score(y_test, y_pred2))\n",
    "# print(\"Recall / Sensifity \", recall_score(y_test, y_pred2))\n",
    "# print(\"F1 \", f1_score(y_test, y_pred2))\n",
    "# tn, fp, fn, tp = confusion_matrix(y_test, y_pred2).ravel()\n",
    "# specificity = tn / (tn+fp)\n",
    "# print(\"Specificity \", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import numpy\n",
    "# numpy.set_printoptions(threshold=sys.maxsize)\n",
    "# print(X_test[:, selected_features_gwo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanpa Seleksi Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm1 = SVC(C=10, gamma=0.1, kernel='rbf')\n",
    "# svm1.fit(X_train, y_train).score(X_test, y_test)\n",
    "# y_pred1 = svm1.predict(X_test)\n",
    "\n",
    "# print(\"Accuracy \", accuracy_score(y_test,y_pred1))\n",
    "# print(\"Precision \", precision_score(y_test, y_pred1))\n",
    "# print(\"Recall / Sensifity \", recall_score(y_test, y_pred1))\n",
    "# print(\"F1 \", f1_score(y_test, y_pred1))\n",
    "# tn, fp, fn, tp = confusion_matrix(y_test, y_pred1).ravel()\n",
    "# specificity = tn / (tn+fp)\n",
    "# print(\"Specificity \", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"list of all selected features: \")\n",
    "# for i, feature in enumerate(data.columns[np.where(selected_features_gwo)], start=1):\n",
    "#     print(f\"{i}. {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from Fitness import Data\n",
    "# import PSO\n",
    "\n",
    "# d = Data('employee_class_on_right.csv',False, 3) # Object for Data\n",
    "# dim = d.getDimension()  # Dimensionality of the Features\n",
    "# selected_pso = PSO.run(d,dim,3) # invoking\n",
    "# selected_pso_bool = selected_pso.astype(bool)\n",
    "# print(selected_pso_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm4 = SVC(C=10, gamma=0.1, kernel='rbf')\n",
    "# svm4.fit(X_train[:, selected_pso_bool], y_train)\n",
    "# y_pred4 = svm4.predict(X_test[:, selected_pso_bool])\n",
    "\n",
    "# print(\"Accuracy \", accuracy_score(y_test,y_pred4))\n",
    "# print(\"Precision \", precision_score(y_test, y_pred4))\n",
    "# print(\"Recall / Sensifity \", recall_score(y_test, y_pred4))\n",
    "# print(\"F1 \", f1_score(y_test, y_pred4))\n",
    "# tn, fp, fn, tp = confusion_matrix(y_test, y_pred4).ravel()\n",
    "# specificity = tn / (tn+fp)\n",
    "# print(\"Specificity \", specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
